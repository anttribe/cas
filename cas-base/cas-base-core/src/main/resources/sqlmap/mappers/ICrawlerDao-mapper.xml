<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd">
<mapper namespace="org.anttribe.cas.base.core.dao.ICrawlerDao">
	<cache readOnly="true" />
	<resultMap id="Crawler-resultMap" type="org.anttribe.cas.base.core.entity.Crawler">
		<id property="id" column="id" />
		<result property="title" column="title" />
		<result property="crawlerUrl" column="crawler_url" />
		<result property="charset" column="charset" />
		<result property="userAgent" column="user_agent" />
		<result property="intervalTime" column="interval_time" />
		<result property="retryTimes" column="retry_times" />
		<result property="timeout" column="timeout" />
		<result property="createTime" column="create_time" />
		<result property="crawlTime" column="crawl_time" />
		<result property="available" column="available" />
		<result property="state" column="state"
			javaType="org.anttribe.cas.base.core.type.CrawlerState" />
		<association property="website"
			javaType="org.anttribe.cas.base.core.entity.Website">
			<id property="id" column="website_id" />
			<result property="siteName" column="website_name" />
		</association>
		<association property="contentType"
			javaType="org.anttribe.cas.base.core.entity.ContentType">
			<id property="id" column="content_type_id" />
			<id property="name" column="content_type_name" />
		</association>
		<collection property="regulars" javaType="java.util.ArrayList"
			ofType="org.anttribe.cas.base.core.entity.CrawlerRegular" column="{crawler.id = id}"
			select="org.anttribe.cas.base.core.dao.ICrawlerRegularDao.find">
		</collection>
	</resultMap>

	<!-- select -->
	<sql id="select">
        <![CDATA[
            SELECT t.id, t.title, t.website, t.crawler_url, t.charset, t.user_agent, t.interval_time, t.retry_times, t.timeout, t.content_type, t.create_time, t.crawl_time, t.state, t.available, t1.id as website_id, t1.site_name as website_name, t2.id as content_type_id, t2.name as content_type_name
              FROM cas_t_core_crawler t
            LEFT JOIN cas_t_core_website t1 on t1.id = t.website
            LEFT JOIN cas_t_core_content_type t2 on t2.id = t.content_type
        ]]>
	</sql>

	<!-- where -->
	<sql id="where">
		<where>
			<if test="null != id and id != ''">
				AND t.id = #{id}
			</if>
			<if test="null != title and title != ''">
				AND t.title LIKE CONCAT('%', '${title}', '%')
			</if>

			<!-- 校验唯一性参数 -->
			<if test="null != notId and '' != notId">
				<![CDATA[ AND t.id <> #{notId} ]]>
			</if>
			<if test="null != uniqueTitle and '' != uniqueTitle">
				AND t.title = #{uniqueTitle}
			</if>
		</where>
	</sql>

	<!-- where-no-alias -->
	<sql id="where-no-alias">
		<where>
			<if test="null != id and id != ''">
				AND id = #{id}
			</if>
		</where>
	</sql>

	<!-- order-by -->
	<sql id="order-by">
	    <![CDATA[ ORDER BY crawl_time DESC, create_time DESC ]]>
	</sql>

	<!-- limit -->
	<sql id="limit">
		<if test="null != pagination">
			limit #{pagination.offset}, #{pagination.pagesize}
		</if>
	</sql>

	<!-- insert: 插入单条数据 -->
	<insert id="insert" parameterType="org.anttribe.cas.base.core.entity.Crawler">
		<selectKey keyProperty="id" resultType="Long" order="AFTER">
		    <![CDATA[ SELECT LAST_INSERT_ID() ]]>
		</selectKey>
		<![CDATA[
		    INSERT INTO cas_t_core_crawler(title, website, crawler_url, charset, user_agent, interval_time, retry_times, timeout, content_type, create_time, crawl_time, state, available)
		        VALUES(#{title}, #{website.id}, #{crawlerUrl}, #{charset}, #{userAgent}, #{intervalTime}, #{retryTimes}, #{timeout}, #{contentType.id}, #{createTime}, #{crawlTime}, #{state}, #{available})
		]]>
	</insert>

	<!-- batchInsert: 批量插入数据 -->
	<insert id="batchInsert" parameterType="java.util.List">
		<![CDATA[
		    INSERT INTO cas_t_core_crawler(title, website, crawler_url, charset, user_agent, interval_time, retry_times, timeout, content_type, create_time, crawl_time, state, available)
		        VALUES
		]]>
		<foreach collection="list" item="item" separator=", ">
			<![CDATA[
			    (#{title}, #{website.id}, #{crawlerUrl}, #{item.charset}, #{item.userAgent}, #{intervalTime}, #{retryTimes}, #{timeout}, #{contentType.id}, #{createTime}, #{crawlTime}, #{state}, #{available})
			]]>
		</foreach>
	</insert>

	<!-- update: 更新单条数据 -->
	<update id="update" parameterType="org.anttribe.cas.base.core.entity.Crawler">
        <![CDATA[
            UPDATE cas_t_core_crawler
        ]]>
		<set>
			<if test="null != title and title != ''">
				title = #{title},
			</if>
			<if test="null != crawlerUrl and crawlerUrl != ''">
				crawler_url = #{crawlerUrl},
			</if>
			charset = #{charset},
			user_agent = #{userAgent},
			<if test="null != intervalTime and intervalTime != ''">
				interval_time = #{intervalTime},
			</if>
			<if test="null != retryTimes and retryTimes != ''">
				retry_times = #{retryTimes},
			</if>
			<if test="null != timeout and timeout != ''">
				timeout = #{timeout},
			</if>
			<if test="null != contentType and contentType.id != ''">
				content_type = #{contentType.id},
			</if>
			<if test="null != crawlTime and crawlTime != ''">
				crawl_time = #{crawlTime},
			</if>
			<if test="null != state and state != ''">
				state = #{state},
			</if>
			<if test="null != available and available != ''">
				available = #{available},
			</if>
		</set>
		<include refid="where-no-alias"></include>
	</update>

	<!-- delete: 删除单条数据 -->
	<delete id="delete" parameterType="Map">
	    <![CDATA[
            DELETE FROM cas_t_core_crawler
        ]]>
		<include refid="where-no-alias"></include>
	</delete>

	<!-- findAll: 查询所有数据 -->
	<select id="findAll" resultMap="Crawler-resultMap">
		<include refid="select"></include>
		<include refid="order-by"></include>
	</select>

	<!-- findById: 根据id查询单条数据 -->
	<select id="findById" resultMap="Crawler-resultMap">
		<include refid="select"></include>
		<include refid="where"></include>
	</select>

	<!-- find: 根据条件查询数据 -->
	<select id="find" resultMap="Crawler-resultMap" parameterType="Map">
		<include refid="select"></include>
		<include refid="where"></include>
		<include refid="order-by"></include>
	</select>

	<!-- count: 根据条件查询数据条数 -->
	<select id="count" resultType="int" parameterType="Map">
		<![CDATA[
            SELECT COUNT(1)
              FROM cas_t_core_crawler t
        ]]>
		<include refid="where"></include>
	</select>

</mapper>